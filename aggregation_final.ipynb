{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import linecache as lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_occurrence(postcodes_list):\n",
    "    '''\n",
    "    This function takes a list of postcodes and creates a dictionary containing a list of aggregated \n",
    "    postcodes, where each postcode chosen was the first occurrence for each of the 15 areas.\n",
    "\n",
    "    The first element simply contains the 15 different postcode areas, the second element of the \n",
    "    dictionary contains the specific postcodes chosen within those areas, and the third element contains\n",
    "    the indices of each of the specific postcodes chosen.  \n",
    "    '''\n",
    "\n",
    "    first_occurrences = {}\n",
    "    \n",
    "    for i, postcode in enumerate(postcodes_list):\n",
    "        prefix = postcode[:2] if len(postcode) >= 2 and postcode[1].isalpha() else (postcode[0] if postcode and postcode[0].isalpha() else '')\n",
    "        # prefix = postcode[:2] if len(postcode) >= 2 and postcode[1].isalpha() else (postcode[0] if postcode[0].isalpha() else '')\n",
    "        if prefix not in first_occurrences:\n",
    "            first_occurrences[prefix] = {'postcode': postcode, 'index': i}\n",
    "    \n",
    "    unique_prefixes = list(first_occurrences.keys())\n",
    "    first_postcodes = [first_occurrences[prefix]['postcode'] for  prefix in unique_prefixes]\n",
    "    first_indices = [first_occurrences[prefix]['index'] for prefix in unique_prefixes]\n",
    "    \n",
    "    return unique_prefixes, first_postcodes, first_indices\n",
    "\n",
    "\n",
    "def extract_selected_values(postcode_list, value_list):\n",
    "\n",
    "    '''\n",
    "    Given a list of postcodes, this performs the above function on that list and then extracts the corresponding \n",
    "    values from the value_list, which could potentially be a list of coordinates, populations or demands.\n",
    "    '''\n",
    "\n",
    "    first_indices = extract_first_occurrence(postcode_list)[2]\n",
    "    return [value_list[i] for i in first_indices]\n",
    "\n",
    "def extract_every_four(postcode_list, value_list):\n",
    "    every_4_indices = [i for i in range(len(postcode_list)) if i%4==0]\n",
    "    return[value_list[i] for i in every_4_indices]\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "def process_aggregated_values(postcode_list, value_list, operation='average'):\n",
    "    \n",
    "    '''\n",
    "    The function takes an unaggergated list of postcodes, a vector of values \n",
    "    and an operation to perform in order to aggregate.\n",
    "\n",
    "    The postcode districts in the postcode list are all aggregated by area, so \n",
    "    for our data the list goes from 440 postcodes to 15.\n",
    "\n",
    "    The value list is then aggregated in accordance with the postcode areas based on the operation entered. \n",
    "\n",
    "    For example, if we choose \"sum\" as an operation, then the function will sum all values within the AB area.\n",
    "    '''\n",
    "    \n",
    "    unique_prefixes = np.unique([postcode[:2] if len(postcode) >= 2 and postcode[1].isalpha() else postcode[0] for postcode in postcode_list])\n",
    "    aggregated_values = np.array([postcode[:2] if len(postcode) >= 2 and postcode[1].isalpha() else postcode[0] for postcode in postcode_list])\n",
    "    \n",
    "    values_dict = {prefix: [] for prefix in unique_prefixes}\n",
    "\n",
    "    for prefix, value in zip(aggregated_values, value_list):\n",
    "        values_dict[prefix].append(value)\n",
    "\n",
    "    if operation == 'average':\n",
    "        result_array = np.array([np.mean(values_dict[prefix]) for prefix in unique_prefixes])\n",
    "    elif operation == 'sum':\n",
    "        result_array = np.array([np.sum(values_dict[prefix]) for prefix in unique_prefixes])\n",
    "    elif operation == 'maximum':\n",
    "        result_array = np.array([np.max(values_dict[prefix]) for prefix in unique_prefixes])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operation. Please choose 'average', 'sum', or 'maximum'.\")\n",
    "\n",
    "    return result_array\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "def process_1D(line_start, line_stop):\n",
    "    \n",
    "    '''\n",
    "    Simply takes the line to start reading, and the line to stop reading. Then, it \n",
    "    processes and transforms the 1D cost and capacity vectors into a format that we can use.\n",
    "    '''\n",
    "    \n",
    "    file = open(r\"CaseStudyData.txt\", \"r\")\n",
    "    costs_og = file.readlines()[line_start-1:line_stop]\n",
    "    costs_og = list(map(lambda s: s.strip(), costs_og))\n",
    "\n",
    "    costs_og = [costs_og[line].split(\" \") for line in range(len(costs_og))]\n",
    "    costs = []\n",
    "    for line in costs_og:\n",
    "        for i in range(len(line)):\n",
    "            costs.append(line[i].strip('[]'))\n",
    "            \n",
    "    costs = costs[2:]        \n",
    "    costs = [eval(cost) for cost in costs]\n",
    "    return costs\n",
    "\n",
    "\n",
    "def process_nD(line_start, line_stop, no_to_delete = None):\n",
    "    \n",
    "    '''\n",
    "    The function reads multiple lines and then process the text to get them \n",
    "    into the form of a long list of values, to be reshaped outside of the function.\n",
    "\n",
    "    The function's purpose is to simply clean the txt data into form suitable for python.\n",
    "    '''\n",
    "    \n",
    "    file = open(r\"CaseStudyData.txt\", \"r\")\n",
    "    list_og = file.readlines()[line_start-1:line_stop]\n",
    "    list_og = list(map(lambda s: s.strip(), list_og))\n",
    "\n",
    "    list_og = [list_og[line].split(\" \") for line in range(len(list_og))]\n",
    "    processed_list = []\n",
    "    for line in list_og:\n",
    "        for i in range(len(line)):\n",
    "            processed_list.append(line[i].strip('[]'))\n",
    "    \n",
    "    if no_to_delete != None:\n",
    "        processed_list = processed_list[no_to_delete:]\n",
    "    else:\n",
    "        pass\n",
    "    return processed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to write txt files\n",
    "\n",
    "The function below simply writes a txt file in the same format as we were given for the original data. The function is written to avoid having large chunks of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_txt(file_path, customer_ids, candidate_ids, \n",
    "              supplier_info1, supplier_info2, \n",
    "              customer_easting, customer_northing, customer_populations,\n",
    "              candidate_easting, candidate_northing, setup_costs, operating_costs, wh_capacities,\n",
    "              demand_prod, demand_prod_year, demand_prod_year_scen,\n",
    "              can_supp_distances, can_cust_distances):\n",
    "    \n",
    "    output_file = file_path\n",
    "\n",
    "    # Writing to the file\n",
    "    with open(output_file, 'w') as file:\n",
    "            \n",
    "        # Write number of customers, locations\n",
    "        file.write(\"! Number of customers = postcode districts\\n\")\n",
    "        file.write(f\"nbCustomers: {len(customer_ids)}\\n\")\n",
    "        file.write(\"! Number of candidate locations\\n\")\n",
    "        file.write(f\"nbCandidates: {len(candidate_ids)}\\n \\n\")\n",
    "        \n",
    "        for i in supplier_info1:\n",
    "            file.write(f\"{i}\")\n",
    "        \n",
    "        for i in supplier_info2:\n",
    "            file.write(f\"{i}\")\n",
    "        \n",
    "        # Write Customer IDs\n",
    "        file.write(\"! Vector of customer ids\\n\")\n",
    "        customer_id_output = \"CustomerId: [ \" + \" \".join('\"' + s + '\"' for s in customer_ids) + \" ]\\n\"\n",
    "        file.write(customer_id_output)\n",
    "\n",
    "        # Write Customer eastings and northings\n",
    "        file.write(\"\\n! Vector of customer coordinates\\n\")\n",
    "        file.write(\"CustomerEasting: [\" )\n",
    "        np.savetxt(file, customer_easting, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n\")\n",
    "        file.write(\"CustomerNorthing: [\" )\n",
    "        np.savetxt(file, customer_northing, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write Customer populations\n",
    "        file.write(\"! Vector of customer populations\\nCustomerPopulation: [ \")\n",
    "        np.savetxt(file, customer_populations, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write Candidate IDs\n",
    "        file.write(\"! Vector of candidate location ids\\n\")\n",
    "        candidate_id_output = \"CandidateId: [ \" + \" \".join('\"' + s + '\"' for s in candidate_ids) + \" ]\\n\"\n",
    "        file.write(candidate_id_output)\n",
    "\n",
    "        # Write Customer eastings and northings\n",
    "        file.write(\"\\n! Vector of candidate location coordinates\\n\")\n",
    "        file.write(\"CandidateEasting: [\" )\n",
    "        np.savetxt(file, candidate_easting, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n\")\n",
    "        file.write(\"CandidateNorthing: [\" )\n",
    "        np.savetxt(file, candidate_northing, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write set up and operating costs\n",
    "        file.write(\"! Setup cost for warehouses\\nSetup: [(1) \")\n",
    "        np.savetxt(file, setup_costs, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "        file.write(\"! Operating cost for warehouses\\nOperating: [(1) \")\n",
    "        np.savetxt(file, operating_costs, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "        file.write(\"! The warehouse capacity\\nCapacity: [(1) \")\n",
    "        np.savetxt(file, wh_capacities, fmt='%d', delimiter=' ', newline=\" \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write annual district demand in kg per product group\n",
    "        file.write(\"! The annual district demand in kilograms per product group\\nCustomerDemand: [\\n\")\n",
    "        for i in range(len(customer_ids)):\n",
    "            file.write(f\"({i+1} 1) {demand_prod[0,i]} {demand_prod[1,i]} {demand_prod[2,i]} {demand_prod[3,i]} \\n\")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write customer demand in kilograms per product group over nbPeriod years\n",
    "        file.write(\"! The customer demand in kilograms per product group over nbPeriods years\\nCustomerDemandPeriods: [\")\n",
    "        for cust in range(len(customer_ids)):\n",
    "            for pro in range(4):\n",
    "                file.write(f\"\\n({cust+1} {pro+1} 1) \")\n",
    "                for per in range(10):\n",
    "                    file.write(f\"{demand_prod_year[pro, per, cust]} \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write customer demand per period for each scenario\n",
    "        file.write(\"CustomerDemandPeriodScenarios: [\")\n",
    "        for cust in range(len(customer_ids)):\n",
    "            for pro in range(4):\n",
    "                for per in range(10):\n",
    "                    file.write(f\"\\n({cust+1} {pro+1} {per+1} 1) \")\n",
    "                    for scen in range(100):\n",
    "                        file.write(f\"{demand_prod_year_scen[pro, per, scen, cust]} \")\n",
    "        file.write(\"] \\n \\n\")\n",
    "\n",
    "        # Write distance matrix between candidate and supplier\n",
    "        file.write(\"! Distance matrix between candidate locations and suppliers\\nDistanceCandidateSupplier: [\")\n",
    "        for can in range(len(candidate_ids)):\n",
    "            file.write(f\"\\n({can+1} 1) \")\n",
    "            for supp in range(53):\n",
    "                file.write(f\"{can_supp_distances[can, supp]} \")\n",
    "        file.write(\"]\\n \\n\")\n",
    "\n",
    "        # Write distance matrix between customer and candidate\n",
    "        file.write(\"! Distance matrix between candidate locations and customers\\nDistanceCandidateCustomer: [\")\n",
    "        for can in range(len(candidate_ids)):\n",
    "            file.write(f\"\\n({can+1} 1) \")\n",
    "            for cust in range(len(customer_ids)):\n",
    "                file.write(f\"{can_cust_distances[can, cust]} \")\n",
    "        file.write(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplier & vehicle information to write txt files\n",
    "\n",
    "These lines are simply read and stored as is from the txt file, as they are only extracted for the purpose of including all the relevant data in our own construction of the txt files later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplier_info1 = open(r\"CaseStudyData.txt\", \"r\").readlines()[4:15]\n",
    "supplier_info2 = open(r\"CaseStudyData.txt\", \"r\").readlines()[33:61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting postcode lists\n",
    "\n",
    "Simply extracting the lists of postcodes for both candidates and customers, and transforming to a form usable in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id_og = lc.getline(r\"CaseStudyData.txt\", 17).split(\" \")[2:-1]\n",
    "customer_id_og = [id.strip('\"') for id in customer_id_og]\n",
    "\n",
    "candidate_id_og = lc.getline(r\"CaseStudyData.txt\", 27).split(\" \")[2:-1]\n",
    "candidate_id_og = [id.strip('\"') for id in candidate_id_og]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data\n",
    "\n",
    "### Extracting coordinates, customer populations and warehouse costs and  capacities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_easting = lc.getline(r\"CaseStudyData.txt\", 20).split(\" \")[2:-1]\n",
    "customer_easting = [eval(coord) for coord in customer_easting]\n",
    "\n",
    "candidate_easting = lc.getline(r\"CaseStudyData.txt\", 30).split(\" \")[2:-1]\n",
    "candidate_easting = [eval(coord) for coord in candidate_easting]\n",
    "\n",
    "customer_northing = lc.getline(r\"CaseStudyData.txt\", 21).split(\" \")[2:-1]\n",
    "customer_northing = [eval(coord) for coord in customer_northing]\n",
    "\n",
    "candidate_northing = lc.getline(r\"CaseStudyData.txt\", 31).split(\" \")[2:-1]\n",
    "candidate_northing = [eval(coord) for coord in candidate_northing]\n",
    "\n",
    "customer_populations = lc.getline(r\"CaseStudyData.txt\", 24).split(\" \")[2:-1]\n",
    "customer_populations = [eval(coord) for coord in customer_populations]\n",
    "\n",
    "setup_costs = process_1D(62, 105)\n",
    "operating_costs = process_1D(108, 146)\n",
    "wh_capacities = process_1D(149, 193)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting multidimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_product = (np.asarray(process_nD(197, 343)).reshape(440, 6)[:, 2:]).astype(int)\n",
    "demand_product_year = (np.asarray(process_nD(347, 1693, 1)).reshape(440, 4, -1)[:, :, 3:]).astype(int)\n",
    "demand_product_year_scenarios = (np.asarray(process_nD(1695, 115666, 1)).reshape(440, 4, 10, -1)[:, :, :, 4:]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_supp_distances = (np.asarray(process_nD(115670, 116109)).reshape(440, -1)[:, 2:]).astype(float)\n",
    "can_cust_distances = (np.asarray(process_nD(116114, 116553)).reshape(440, -1)[:, 2:]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating over customers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the customer and candidate IDs\n",
    "customer_id_selective = extract_first_occurrence(customer_id_og)\n",
    "candidate_id_selective = extract_first_occurrence(candidate_id_og)\n",
    "\n",
    "# indices for the first occurrences of each postcode area\n",
    "aggregation_indices = customer_id_selective[2]\n",
    "\n",
    "\n",
    "# AGGREGATING COORDINATES AND POPULATION \n",
    "customer_easting_agg = extract_selected_values(customer_id_og, customer_easting)\n",
    "customer_northing_agg = extract_selected_values(customer_id_og, customer_northing)\n",
    "customer_populations_agg = process_aggregated_values(customer_id_og, customer_populations, \"sum\")\n",
    "\n",
    "\n",
    "# AGGREGATING DEMAND MATRICES\n",
    "demand_prod_sel = []\n",
    "for i in range(4):\n",
    "    demand_prod_sel.append(process_aggregated_values(customer_id_og, demand_product[:,i], \"sum\"))\n",
    "demand_prod_sel = np.asarray(demand_prod_sel)\n",
    "\n",
    "demand_prod_year_sel = []\n",
    "for i in range(4):\n",
    "    dpp_sel = []\n",
    "    for j in range(10):\n",
    "        dpp_sel.append(process_aggregated_values(customer_id_og, demand_product_year[:, i, j], \"sum\"))\n",
    "    demand_prod_year_sel.append(dpp_sel)\n",
    "demand_prod_year_sel = np.asarray(demand_prod_year_sel)\n",
    "\n",
    "demand_prod_year_scen_sel = []\n",
    "for i in range(4):\n",
    "    dpy_sel = []\n",
    "    for j in range(10):\n",
    "        dp_sel = []\n",
    "        for k in range(100):\n",
    "            dp_sel.append(process_aggregated_values(customer_id_og, demand_product_year_scenarios[:, i, j, k], \"sum\"))\n",
    "        dpy_sel.append(dp_sel)\n",
    "    demand_prod_year_scen_sel.append(dpy_sel)  \n",
    "demand_prod_year_scen_sel = np.asarray(demand_prod_year_scen_sel)\n",
    "\n",
    "\n",
    "# AGGREGATING DISTANCE MATRIX \n",
    "agg_dist_customer_only = np.asarray([can_cust_distances[:,i] for i in aggregation_indices]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing data to a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a txt file aggregating over customers only\n",
    "write_txt(file_path = f\"Datasets/CaseStudyData_Aggregated_CustomerOnly.txt\",\n",
    "          customer_ids=customer_id_selective[0], \n",
    "          candidate_ids=candidate_id_og,\n",
    "          supplier_info1=supplier_info1, \n",
    "          supplier_info2=supplier_info2,\n",
    "          customer_easting=customer_easting_agg, \n",
    "          customer_northing=customer_northing_agg, \n",
    "          customer_populations=customer_populations_agg,\n",
    "          candidate_easting=candidate_easting, \n",
    "          candidate_northing=candidate_northing, \n",
    "          setup_costs=setup_costs, \n",
    "          operating_costs=operating_costs, \n",
    "          wh_capacities=wh_capacities,\n",
    "          demand_prod=demand_prod_sel, \n",
    "          demand_prod_year=demand_prod_year_sel, \n",
    "          demand_prod_year_scen=demand_prod_year_scen_sel,\n",
    "          can_supp_distances=can_supp_distances, \n",
    "          can_cust_distances=agg_dist_customer_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating over both customers and candidates\n",
    "\n",
    "#### All the customer aggregations can be obtained from the code chunk above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGGREGATING COORDINATES\n",
    "candidate_easting_agg = np.asarray([candidate_easting[i] for i in aggregation_indices])\n",
    "candidate_northing_agg = np.asarray([candidate_northing[i] for i in aggregation_indices])\n",
    "\n",
    "\n",
    "# AGGREGATING COSTS AND CAPACITIES\n",
    "\n",
    "setup_costs_agg = np.asarray([setup_costs[i] for i in aggregation_indices])\n",
    "operating_costs_agg = np.asarray([operating_costs[i] for i in aggregation_indices])\n",
    "wh_capacities_agg = np.asarray([wh_capacities[i] for i in aggregation_indices])\n",
    "\n",
    "\n",
    "# AGGREGATING DISTANCE MATRIX\n",
    "agg_dist_can_cust = np.asarray([agg_dist_customer_only[i,:] for i in aggregation_indices])\n",
    "agg_dist_can_supp = np.asarray([can_supp_distances[i,:] for i in aggregation_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing data to .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a txt file aggregating both\n",
    "write_txt(file_path=f\"Datasets/CaseStudyData_Aggregated_Both.txt\",\n",
    "          customer_ids=customer_id_selective[0], \n",
    "          candidate_ids=candidate_id_selective[0],\n",
    "          supplier_info1=supplier_info1, \n",
    "          supplier_info2=supplier_info2,\n",
    "          customer_easting=customer_easting_agg, \n",
    "          customer_northing=customer_northing_agg, \n",
    "          customer_populations=customer_populations_agg,\n",
    "          candidate_easting=candidate_easting_agg, \n",
    "          candidate_northing=candidate_northing_agg, \n",
    "          setup_costs=setup_costs_agg, \n",
    "          operating_costs=operating_costs_agg, \n",
    "          wh_capacities=wh_capacities_agg,\n",
    "          demand_prod=demand_prod_sel, \n",
    "          demand_prod_year=demand_prod_year_sel, \n",
    "          demand_prod_year_scen=demand_prod_year_scen_sel,\n",
    "          can_supp_distances=agg_dist_can_supp, \n",
    "          can_cust_distances=agg_dist_can_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing optimal candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No aggregation on customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_candidates_ind = [41, 47, 53, 182, 314, 400] # the candidates we wish to fix\n",
    "fixed_candidates = [candidate_id_og[i] for i in fixed_candidates_ind]\n",
    "\n",
    "candidate_easting_fixed = np.asarray([candidate_easting[i] for i in fixed_candidates_ind])\n",
    "candidate_northing_fixed = np.asarray([candidate_northing[i] for i in fixed_candidates_ind])\n",
    "\n",
    "setup_costs_fixed = np.asarray([setup_costs[i] for i in fixed_candidates_ind])\n",
    "operating_costs_fixed = np.asarray([operating_costs[i] for i in fixed_candidates_ind])\n",
    "wh_capacities_fixed = np.asarray([wh_capacities[i] for i in fixed_candidates_ind])\n",
    "\n",
    "fixed_can_supp_dist = np.asarray([can_supp_distances[i,:] for i in fixed_candidates_ind])\n",
    "fixed_can_cust_dist = np.asarray([can_cust_distances[i,:] for i in fixed_candidates_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write data to .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a txt file fixing candidates and keeping all customers unaggregated\n",
    "write_txt(file_path=f\"Datasets/CaseStudy_FixedCandidates_NoAggregation.txt\",\n",
    "          customer_ids=customer_id_og, \n",
    "          candidate_ids=fixed_candidates,\n",
    "          supplier_info1=supplier_info1, \n",
    "          supplier_info2=supplier_info2,\n",
    "          customer_easting=customer_easting, \n",
    "          customer_northing=customer_northing, \n",
    "          customer_populations=customer_populations,\n",
    "          candidate_easting=candidate_easting_fixed, \n",
    "          candidate_northing=candidate_northing_fixed, \n",
    "          setup_costs=setup_costs_fixed, \n",
    "          operating_costs=operating_costs_fixed, \n",
    "          wh_capacities=wh_capacities_fixed,\n",
    "          demand_prod=demand_product.T, \n",
    "          demand_prod_year=np.transpose(demand_product_year,(1,2,0)), \n",
    "          demand_prod_year_scen=np.transpose(demand_product_year_scenarios,(1,2,3,0)),\n",
    "          can_supp_distances=fixed_can_supp_dist, \n",
    "          can_cust_distances=fixed_can_cust_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_ccd_agg = np.asarray([agg_dist_customer_only[i,:] for i in fixed_candidates_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing data to .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a txt file fixing candidates and aggregating customers\n",
    "write_txt(file_path=f\"Datasets/CaseStudy_FixedCandidates_WithAggregation.txt\",\n",
    "          customer_ids=customer_id_selective[0], \n",
    "          candidate_ids=fixed_candidates,\n",
    "          supplier_info1=supplier_info1, \n",
    "          supplier_info2=supplier_info2,\n",
    "          customer_easting=customer_easting_agg, \n",
    "          customer_northing=customer_northing_agg, \n",
    "          customer_populations=customer_populations_agg,\n",
    "          candidate_easting=candidate_easting_fixed, \n",
    "          candidate_northing=candidate_northing_fixed, \n",
    "          setup_costs=setup_costs_fixed, \n",
    "          operating_costs=operating_costs_fixed, \n",
    "          wh_capacities=wh_capacities_fixed,\n",
    "          demand_prod=demand_prod_sel, \n",
    "          demand_prod_year=demand_prod_year_sel, \n",
    "          demand_prod_year_scen=demand_prod_year_scen_sel,\n",
    "          can_supp_distances=fixed_can_supp_dist, \n",
    "          can_cust_distances=fixed_ccd_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (uncertain demands)\n",
    "\n",
    "## Aggregating customers normally and candidates for every 4th value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_fourth_ind = [i for i in range(len(candidate_id_og)) if i % 4 == 3]\n",
    "agg4_candidates = [candidate_id_og[i] for i in every_fourth_ind]\n",
    "\n",
    "# AGGREGATING COORDINATES\n",
    "candidate_easting_agg4 = np.asarray([candidate_easting[i] for i in every_fourth_ind])\n",
    "candidate_northing_agg4 = np.asarray([candidate_northing[i] for i in every_fourth_ind])\n",
    "\n",
    "\n",
    "# AGGREGATING COSTS AND CAPACITIES\n",
    "\n",
    "setup_costs_agg4 = np.asarray([setup_costs[i] for i in every_fourth_ind])\n",
    "operating_costs_agg4 = np.asarray([operating_costs[i] for i in every_fourth_ind])\n",
    "wh_capacities_agg4 = np.asarray([wh_capacities[i] for i in every_fourth_ind])\n",
    "\n",
    "\n",
    "# AGGREGATING DISTANCE MATRIX\n",
    "agg_dist_can_cust4 = np.asarray([agg_dist_customer_only[i,:] for i in every_fourth_ind])\n",
    "agg_dist_can_supp4 = np.asarray([can_supp_distances[i,:] for i in every_fourth_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing data to .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a txt file choosing every 4th candidate with aggregated customers\n",
    "write_txt(file_path=f\"Datasets/CaseStudy_AggData_110_candidates.txt\",\n",
    "          customer_ids=customer_id_selective[0], \n",
    "          candidate_ids=agg4_candidates,\n",
    "          supplier_info1=supplier_info1, \n",
    "          supplier_info2=supplier_info2,\n",
    "          customer_easting=customer_easting_agg, \n",
    "          customer_northing=customer_northing_agg, \n",
    "          customer_populations=customer_populations_agg,\n",
    "          candidate_easting=candidate_easting_agg4, \n",
    "          candidate_northing=candidate_northing_agg4, \n",
    "          setup_costs=setup_costs_agg4, \n",
    "          operating_costs=operating_costs_agg4, \n",
    "          wh_capacities=wh_capacities_agg4,\n",
    "          demand_prod=demand_prod_sel, \n",
    "          demand_prod_year=demand_prod_year_sel, \n",
    "          demand_prod_year_scen=demand_prod_year_scen_sel,\n",
    "          can_supp_distances=agg_dist_can_supp4, \n",
    "          can_cust_distances=agg_dist_can_cust4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating customers normally and candidates for every 2nd value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_second_ind = [i for i in range(len(candidate_id_og)) if i % 2 == 1]\n",
    "agg2_candidates = [candidate_id_og[i] for i in every_second_ind]\n",
    "\n",
    "# AGGREGATING COORDINATES\n",
    "candidate_easting_agg2 = np.asarray([candidate_easting[i] for i in every_second_ind])\n",
    "candidate_northing_agg2 = np.asarray([candidate_northing[i] for i in every_second_ind])\n",
    "\n",
    "\n",
    "# AGGREGATING COSTS AND CAPACITIES\n",
    "\n",
    "setup_costs_agg2 = np.asarray([setup_costs[i] for i in every_second_ind])\n",
    "operating_costs_agg2 = np.asarray([operating_costs[i] for i in every_second_ind])\n",
    "wh_capacities_agg2 = np.asarray([wh_capacities[i] for i in every_second_ind])\n",
    "\n",
    "\n",
    "# AGGREGATING DISTANCE MATRIX\n",
    "agg_dist_can_cust2 = np.asarray([agg_dist_customer_only[i,:] for i in every_second_ind])\n",
    "agg_dist_can_supp2 = np.asarray([can_supp_distances[i,:] for i in every_second_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing data to a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a txt file choosing every other candidate with aggregated customers\n",
    "write_txt(file_path=f\"Datasets/CaseStudy_AggData_220_candidates.txt\",\n",
    "          customer_ids=customer_id_selective[0], \n",
    "          candidate_ids=agg2_candidates,\n",
    "          supplier_info1=supplier_info1, \n",
    "          supplier_info2=supplier_info2,\n",
    "          customer_easting=customer_easting_agg, \n",
    "          customer_northing=customer_northing_agg, \n",
    "          customer_populations=customer_populations_agg,\n",
    "          candidate_easting=candidate_easting_agg2, \n",
    "          candidate_northing=candidate_northing_agg2, \n",
    "          setup_costs=setup_costs_agg2, \n",
    "          operating_costs=operating_costs_agg2, \n",
    "          wh_capacities=wh_capacities_agg2,\n",
    "          demand_prod=demand_prod_sel, \n",
    "          demand_prod_year=demand_prod_year_sel, \n",
    "          demand_prod_year_scen=demand_prod_year_scen_sel,\n",
    "          can_supp_distances=agg_dist_can_supp2, \n",
    "          can_cust_distances=agg_dist_can_cust2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
